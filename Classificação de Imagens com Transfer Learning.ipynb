{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeLsQmVapzONID7AR/Bpwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ka1ux/Transfer_learning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "8yjX3iCz4qot"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e70e9a0"
      },
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# 1. Montar o Google Drive (com remontagem forçada para garantir)\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. Explorar a estrutura do Google Drive para encontrar o caminho correto\n",
        "print(\"\\nConteúdo do diretório raiz do Drive:\")\n",
        "try:\n",
        "    print(os.listdir('/content/drive/MyDrive/'))\n",
        "except FileNotFoundError:\n",
        "    print(\"Could not list contents of /content/drive/MyDrive/. Ensure Google Drive is mounted correctly.\")\n",
        "\n",
        "# 3. Definir possíveis caminhos alternativos\n",
        "possible_paths = [\n",
        "    '/content/drive/MyDrive/minhas_imagens',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/minhas_imagens',\n",
        "    '/content/drive/MyDrive/Datasets/minhas_imagens',\n",
        "    '/content/drive/MyDrive/Imagens/minhas_imagens'\n",
        "]\n",
        "\n",
        "# 4. Encontrar o caminho correto automaticamente\n",
        "base_dir = None\n",
        "for path in possible_paths:\n",
        "    if os.path.exists(path):\n",
        "        base_dir = path\n",
        "        print(f\"\\nDiretório encontrado em: {path}\")\n",
        "        break\n",
        "\n",
        "if base_dir is None:\n",
        "    print(\"\\nERRO: Não foi possível encontrar o diretório 'minhas_imagens'\")\n",
        "    print(\"Sugestões:\")\n",
        "    print(\"1. Verifique se o nome da pasta está correto\")\n",
        "    print(\"2. Confira se as imagens estão em '/content/drive/MyDrive/'\")\n",
        "    print(\"3. A pasta deve conter subfolders for each class (e.g., 'cats', 'dogs')\")\n",
        "    print(\"\\nConteúdo completo do seu Drive:\")\n",
        "    try:\n",
        "        print(os.listdir('/content/drive/MyDrive/'))\n",
        "    except FileNotFoundError:\n",
        "        print(\"Could not list contents of /content/drive/MyDrive/. Ensure Google Drive is mounted correctly.\")\n",
        "    raise FileNotFoundError(\"Diretório 'minhas_imagens' não encontrado\")\n",
        "\n",
        "# 5. Verificar a estrutura das pastas\n",
        "print(\"\\nEstrutura encontrada:\")\n",
        "try:\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            try:\n",
        "                num_images = len(os.listdir(item_path))\n",
        "                print(f\"{item}: {num_images} imagens\")\n",
        "            except OSError as e:\n",
        "                print(f\"Error listing images in {item}: {e}\")\n",
        "except OSError as e:\n",
        "    print(f\"Error listing contents of directory {base_dir}: {e}\")\n",
        "\n",
        "\n",
        "# 6. Parâmetros do modelo\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# 7. Pré-processamento com aumento de dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator( # Use a separate generator for validation without augmentation\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# 8. Carregar imagens usando os geradores\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary', # Assuming binary classification\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory( # Use val_datagen here\n",
        "    base_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary', # Assuming binary classification\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Verificar as classes encontradas\n",
        "print(\"\\nClasses encontradas:\", train_generator.class_indices)\n",
        "\n",
        "\n",
        "# 9. Criar modelo Xception (ou outro modelo pré-treinado)\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False # Congelar as camadas convolucionais\n",
        "\n",
        "# 10. Adicionar camadas de classificação ao modelo base\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid') # Camada de saída para classificação binária\n",
        "])\n",
        "\n",
        "# 11. Compilar o modelo\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy', # Função de perda para classificação binária\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 12. Treinar o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "# 13. Avaliar o modelo\n",
        "print(\"\\nAvaliando o modelo...\")\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'\\nAcurácia no conjunto de validação: {accuracy * 100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
